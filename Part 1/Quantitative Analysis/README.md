#quantitative_analysis
#part1

# Overview

- Discrete and continuous probability distributions
- Estimating the parameters of distributions
- Population and sample statistics
- Bayesian analysis
- Statistical inference and hypothesis testing
- Measures of correlation
- Linear regression with single and multiple regressors
- Time series analysis and forecasting
- Simulation methods
- Machine learning

## Readings

- Global Association of Risk Professionals, Quantitative Analysis (New York, NY: Pearson, 2022)
	- Chapter 1: Fundamentals of Probability 
		- Describe an event and an event space.
		- Describe independent events and mutually exclusive events.
		- Explain the difference between independent events and conditionally independent events.
		- Calculate the probability of an event for a discrete probability function.
		- Define, describe, and calculate a conditional probability.
		- Differentiate between conditional and unconditional probabilities.
		- Explain and apply Bayes’ rule.
	- Chapter 2: Random Variables
		- Describe and differentiate a probability mass function from a cumulative distribution function and explain the relationship between the two.
		- Describe and apply the concept of a mathematical expectation of a random variable.
		- Describe the four common population moments.
		- Explain the differences between a probability mass function and a probability density function.
		- Describe the quantile function and quantile-based estimators.
		- Explain the effect of a linear transformation of a random variable on the mean, variance, standard deviation, skewness, kurtosis, median, and interquartile range.
	- Chapter 3: Common Univariate Random Variables
		- Illustrate the key properties and applications of the following distributions: Bernoulli, binomial, Poisson, uniform, normal, lognormal, Chi-squared, Student’s t, F, exponential, and Beta distributions.
		- Construct mixture distributions, and explain the creation and characteristics of mixture distributions.
	- Chapter 4: Multivariate Random Variables
		- Explain how a probability matrix can be used to express a probability mass function.
		- Calculate the marginal and conditional distributions of a discrete bivariate random variable.
		- Explain how the expectation of a function is calculated for a bivariate discrete random variable.
		- Define covariance and explain what it measures.
		- Explain the relationship between covariance and correlation of two random variables, and how these are related to independence.
		- Explain and illustrate the effects of linear transformations on covariance and correlation.
		- Calculate the variance of a weighted sum of two random variables.
		- Calculate the conditional expectation of a component of a bivariate random variable.
		- Describe features of an independent and identically distributed (iid) sequence of random variables.
		- Explain and illustrate how the iid property simplifies calculation of mean and variance of a sum of iid random variables.
	- Chapter 5: Sample Moments
		- Estimate the mean, variance, and standard deviation using sample data.
		- Explain the difference between a population moment and a sample moment.
		- Differentiate between an estimator and an estimate.
		- Describe the bias of an estimator and explain what the bias measures.
		- Explain what is meant by the statement that the mean estimator is BLUE.
		- Describe the consistency of an estimator and explain its usefulness.
		- Explain how the Law of Large Numbers (LLN) and Central Limit Theorem (CLT) apply to the sample mean.
		- Estimate and interpret the skewness and kurtosis of a random variable.
		- Estimate quantiles, including the median, using sample data.
		- Estimate the mean of two variables and apply the CLT.
		- Estimate the covariance and correlation between two random variables.
		- Explain how coskewness and cokurtosis are related to skewness and kurtosis.
	- Chapter 6: Hypothesis Testing
		- 

